# -*- coding: utf-8 -*-
"""GOOD COPY Bixi Challenge

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ADmu8Z-9LJMJbhxM4gTI8lnI6c1QJreo

# Bixi Challenge

By Vanessa DiPietrantonio and Gabrielle Guidote

## Bixi Links
"""

data_urls = {
  "2014": "https://sitewebbixi.s3.amazonaws.com/uploads/docs/biximontrealrentals2014-f040e0.zip",
  "2015": "https://sitewebbixi.s3.amazonaws.com/uploads/docs/biximontrealrentals2015-69fdf0.zip",
  "2016": "https://sitewebbixi.s3.amazonaws.com/uploads/docs/biximontrealrentals2016-912f00.zip",
  "2017": "https://sitewebbixi.s3.amazonaws.com/uploads/docs/biximontrealrentals2017-d4d086.zip",
  "2018": "https://sitewebbixi.s3.amazonaws.com/uploads/docs/biximontrealrentals2018-96034e.zip",
  "2019": "https://sitewebbixi.s3.amazonaws.com/uploads/docs/biximontrealrentals2019-33ea73.zip",
}

"""## Load the Data"""

import io
import pandas as pd
import requests
import zipfile
import matplotlib.pyplot as plt

df = None
for year, url in data_urls.items():
  print("Processing {}".format(year))
  # Load the url
  response = requests.get(url)
  # Read the archive from the response
  archive = zipfile.ZipFile(io.BytesIO(response.content))
  # Loop over all the files in the archive
  for file in archive.namelist():
    # Check that we are looking at one of the files we want
    if not archive.getinfo(file).is_dir() and "Station" not in file:
      print("Loading data from: {}".format(file))
      # We will load the start_date column only to save on memory use
      try:
        current_length = len(df)
        df = df.append(
          pd.read_csv(archive.open(file), usecols=["start_date"]),
          ignore_index=True, 
        )
      except:
        current_length = 0
        df = pd.read_csv(archive.open(file), usecols=["start_date"])
      print(" > {} rows processed".format(len(df) - current_length))
  response.close()

"""### Convert to Dataset"""

df["start_date"] = pd.to_datetime(df["start_date"])

df.describe()

df.info()

"""### Bixi bikes used vs day of the year"""

df["date"] = pd.to_datetime(df['start_date']).dt.date
df['time'] = pd.to_datetime(df['start_date']).dt.time
df.head()

df["day"] = df["start_date"].dt.dayofyear
df.head()

date_df = df['day'].value_counts(normalize=True).sort_index()
date_df

plt.figure(figsize=[21,9], dpi=300)
plt.bar(date_df.index, date_df.values)
plt.show()

"""### Biki bikes vs day of week"""

df['weekday'] = df['start_date'].dt.day_name()
df.head()

df['weekday'].unique()

day_df = df['weekday'].value_counts(normalize=True)
day_df

day_df = day_df.reindex(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])
day_df

plt.figure(figsize=[21,9], dpi=300)
plt.bar(day_df.index, day_df.values)
plt.show()

"""### Bixi bikes used vs month"""

df["month"] = df["start_date"].dt.month
df.head()

month_df = df['month'].value_counts(normalize=True).sort_index()
month_df

plt.figure(figsize=[21,9], dpi=300)
plt.bar(month_df.index, month_df.values)
plt.show()

df = df.set_index('date')
df.head()

"""### Target Vector"""

target_df = df.groupby('date').size()
target_df

"""### Feature Vector"""

feature_df = pd.get_dummies(df.groupby("date").first(), columns=['weekday'], prefix="", prefix_sep="").loc[:,['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']]
feature_df

feature_df = feature_df.merge(pd.get_dummies(df.groupby("date").first(), columns=['month'], prefix="", prefix_sep="").loc[:,['4','5','6','7','8','9','10','11']], on='date')
feature_df

feature_df = feature_df.rename(columns={'4': 'April', '5':'May','6':'June','7':'July','8':'August','9':'September','10':'October','11':'November'})
feature_df

"""## Model"""

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model

features_matrix = feature_df.drop(columns=["Sunday", "April"])
features_matrix

model.fit(features_matrix, target_df)

model.coef_

model.intercept_

params = pd.Series(model.coef_, index=features_matrix.columns)
params

plt.figure(figsize=[21,9], dpi=300)
plt.plot(features_matrix.index, target_df, features_matrix.index, model.predict(features_matrix))
plt.show()

# 2019 only
from matplotlib import dates as mdate
plt.figure(figsize=[21,9], dpi=300)
plt.plot(features_matrix.index, target_df, features_matrix.index, model.predict(features_matrix))
plt.xlim(left=mdate.datestr2num("2019-01-01"), right=mdate.datestr2num("2019-12-31"))
plt.show()

import numpy as np
from sklearn.utils import resample
np.random.seed(1)
uncertainty = np.std([model.fit(*resample(features_matrix, target_df)).coef_ for i in range(1000)], 0)
params = pd.Series(uncertainty, index=features_matrix.columns)
params

#Average number of daily trips
#Target mean per day
target_mean = target_df.mean()
print(target_mean)

import math
from sklearn.metrics import mean_squared_error

features_matrix.index = pd.to_datetime(features_matrix.index)
target_df.index = pd.to_datetime(target_df.index)

error = mean_squared_error(model.predict(features_matrix.loc[features_matrix.index.year == 2019]), target_df.loc[target_df.index.year == 2019])
print(math.sqrt(error)/target_mean * 100)


model.fit(features_matrix.loc[features_matrix.index.year < 2019], target_df.loc[target_df.index.year < 2019])
error = mean_squared_error(model.predict(features_matrix.loc[features_matrix.index.year == 2019]), target_df.loc[target_df.index.year == 2019])
print(math.sqrt(error)/target_mean * 100)

"""###Adding Precipitation and Temperature"""

# Montreal (Mirabel)
station_id = 48374

# Initialize df with 2012 data
meteo_df = pd.read_csv("https://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv&stationID={}&Year={}&Day=14&timeframe=2&submit=Download+Data".format(station_id, 2012))

# Append other years
for year in range(2014, 2020):
  meteo_df = meteo_df.append(pd.read_csv("https://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv&stationID={}&Year={}&Day=14&timeframe=2&submit=Download+Data".format(station_id, year)))

meteo_df.head()

weather_features_df = meteo_df[["Date/Time", "Mean Temp (Â°C)", "Total Precip (mm)"]]
weather_features_df.info()

weather_features_df = weather_features_df.fillna(method="pad")
weather_features_df.isnull().describe()

weather_features_df = weather_features_df.set_index("Date/Time")
weather_features_df.head()

features_matrix = features_matrix.join(weather_features_df)
features_matrix.head()

from matplotlib.patches import Rectangle

def run_model(_matrix, _target, label):

  # Run model and calculate error
  model.fit(_matrix.loc[_matrix.index.year<2019], _target.loc[_target.index.year<2019])
  error = mean_squared_error(model.predict(_matrix.loc[_matrix.index.year == 2019]), _target.loc[_target.index.year == 2019])

  # Draw plot
  plt.figure(figsize=[21,12], dpi=300)
  plt.plot(_matrix.index, _target, _matrix.index, model.predict(_matrix), linewidth=1)
  plt.xlim(left=mdate.datestr2num("2018-01-01"), right=mdate.datestr2num("2019-11-30"))
  top = 50000
  plt.ylim(bottom=0, top=top)

  # Add info
  try:
    text_str = "Intercept: {:.1f}".format(model.intercept_)
    for i, row in enumerate(pd.Series(model.coef_, index=_matrix.columns).iteritems()):
      text_str += "\n{}: {:.1f}".format(row[0], row[1])  
  except:
    text_str = ""

  plt.text(
    x=mdate.datestr2num("2019-11-20"),
    y=top-1000,
    s=text_str,
    bbox=dict(facecolor='gray', alpha=0.2),
    verticalalignment='top',
    horizontalalignment='right'
  )
  plt.annotate(
    label,
    xy=(mdate.datestr2num("2018-01-06"), top-2000),
    fontsize=18,
    fontweight='heavy'
  )
  plt.annotate(
    "RMSE = {:.2f}".format(math.sqrt(error)/target_mean * 100),
    xy=(mdate.datestr2num("2019-01-06"), top-2000),
    fontsize=14,
  )
  plt.annotate(
    "Training",
    xy=(mdate.datestr2num("2018-01-06"), 1000),
    fontsize=10,
  )
  plt.annotate(
    "Testing",
    xy=(mdate.datestr2num("2019-01-06"), 1000),
    fontsize=10,
  )

  rect = Rectangle((mdate.datestr2num("2018-01-01"), 0), 365, 50000, facecolor="black", alpha=0.05)
  plt.gca().add_patch(rect)

  plt.show()

run_model(features_matrix, target_df, "Include temperature and precipitation")

"""### Tour d'Ile Montreal and Other Holidays"""

from dateutil.relativedelta import MO
from pandas.tseries.holiday import AbstractHolidayCalendar, GoodFriday, EasterMonday, Holiday, nearest_workday, next_monday, sunday_to_monday
from pandas.tseries.offsets import CustomBusinessDay
from dateutil.relativedelta import FR, MO, SA, SU, TH, TU, WE  

class MontrealHolidayCalendar(AbstractHolidayCalendar):
  rules = [
    Holiday("New Year's Day", month=1, day=1, observance=next_monday),
    GoodFriday,
    EasterMonday,
    Holiday("Jour des Patriotes", month=5, day=24, offset=pd.DateOffset(weekday=MO(-1))),
    Holiday("St. Jean Baptiste", month=6, day=24, observance=nearest_workday),
    Holiday("Canada Day", month=7, day=1, observance=nearest_workday),
    Holiday("Labor Day", month=9, day=1, offset=pd.DateOffset(weekday=MO(1))),
    Holiday("Thanksgiving", month=10, day=1, offset=pd.DateOffset(weekday=MO(2))),
    Holiday("Christmas Day", month=12, day=25, observance=sunday_to_monday),
    Holiday("Tour d'Ile Montreal", month=6, day=2, offset=pd.DateOffset(weekday=SU(1)))
  ]  

MontrealHolidayCalendar().holidays(start="2019-01-01", end="2019-12-31")

features_matrix['holidays'] = features_matrix.index.isin(MontrealHolidayCalendar().holidays(start="2014-01-01", end="2019-12-31")).astype(int)
features_matrix

run_model(features_matrix, target_df, "Include Tour d'Ile de Montreal and other holidays")

"""### Bixi bikes used vs year"""

year_df = df.groupby(df['start_date'].dt.year).size()
plt.figure(figsize=[21,9], dpi=300)
plt.bar(year_df.index, year_df.values)
plt.yticks(
    ticks=[1000000, 2000000, 3000000, 4000000, 5000000], 
    labels=[1000000, 2000000, 3000000, 4000000, 5000000]
)

plt.show()

#After 2016, Bixi was rentable by Opus, thus more accessible
features_matrix["After 2016"] = (features_matrix.index.year > 2016).astype(int)
features_matrix.head()

run_model(features_matrix, target_df, "Considering Opus passes for Bixi (2016-2017)")

# New docking stations implimented in 2018, which holds twice the capacity of bikes than current station
features_matrix["After 2017"] = (features_matrix.index.year > 2017).astype(int)
features_matrix.head()

run_model(features_matrix, target_df, "Considering Implimentation of New Docking Stations")

features_matrix["Year of Operation"] = (features_matrix.index.year - 2013).astype(int)
features_matrix.head()

run_model(features_matrix, target_df, "Includes Year of Operation")